{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37048918-06b4-4702-9c2a-6b804911b5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.66.5)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b35cdaf-9582-4d07-96dd-601567b447a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPORT STATEMENTS\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcbf3616-9e22-46d1-b3d5-13f81f927c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_transcript(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # Ensure 'Transkript' column has no NaN values\n",
    "    data['Transkript'] = data['Transkript'].fillna(\"\").astype(str)\n",
    "\n",
    "    # Chunking logic\n",
    "    chunked_data = []\n",
    "    current_speaker = None\n",
    "    current_text = \"\"\n",
    "    initial_timestamp = \"\"\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        speaker = row['Sprecher']\n",
    "        transcript = row['Transkript']\n",
    "        timestamp = row['Timecode'] \n",
    "\n",
    "        if speaker != current_speaker:\n",
    "            # Save previous chunk if exists\n",
    "            if current_speaker is not None:\n",
    "                chunked_data.append({\n",
    "                    'Speaker': current_speaker,\n",
    "                    'Transcript': current_text.strip(),\n",
    "                    'Initial_Timestamp' : initial_timestamp,\n",
    "                    'Current_Timestamp' : timestamp\n",
    "                })\n",
    "            \n",
    "            # Start a new chunk\n",
    "            current_speaker = speaker\n",
    "            current_text = transcript\n",
    "            initial_timestamp = timestamp \n",
    "        else:\n",
    "            # Continue appending to the same speaker's chunk\n",
    "            current_text += \" \" + transcript if isinstance(transcript, str) else \"\"\n",
    "\n",
    "    # Save the last chunk\n",
    "    if current_speaker is not None:\n",
    "        chunked_data.append({\n",
    "            'Speaker': current_speaker,\n",
    "            'Transcript': current_text.strip(),\n",
    "            'Initial_Timestamp' : initial_timestamp,\n",
    "            'Current_Timestamp' : timestamp\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    chunked_df = pd.DataFrame(chunked_data)\n",
    "    \n",
    "    return chunked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deee020a-14b6-4de1-b9cb-58980f35d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_sentence(chunked_df: pd.DataFrame, min_tokens=256, max_tokens=512) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Further splits chunks by sentence while ensuring each chunk is within a token range.\n",
    "\n",
    "    Args:\n",
    "        chunked_df (pd.DataFrame): Input DataFrame with 'Speaker' and 'Transcript' columns.\n",
    "        min_tokens (int): Minimum number of tokens per chunk.\n",
    "        max_tokens (int): Maximum number of tokens per chunk.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with sentence-based chunked transcripts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Function to count tokens (approximate, assuming 1 word ≈ 1.2 tokens)\n",
    "    def count_tokens(text):\n",
    "        return len(text.split()) * 1.2  # Rough estimate\n",
    "\n",
    "    # Initialize list for final merged chunks\n",
    "    merged_chunks = []\n",
    "    temp_chunk = []\n",
    "    temp_token_count = 0\n",
    "    speaker = None\n",
    "    initial_timestamp = \"\"\n",
    "    final_timestamp = \"\"\n",
    "\n",
    "    # Process each row\n",
    "    for _, row in chunked_df.iterrows():\n",
    "        sentence = row['Transcript']\n",
    "        sentence_tokens = count_tokens(sentence)\n",
    "\n",
    "        # If adding this chunk keeps us within MAX_TOKENS\n",
    "        if temp_token_count + sentence_tokens <= max_tokens:\n",
    "            if not temp_chunk:\n",
    "                speaker = row['Speaker']  # Store speaker only for new chunks\n",
    "                initial_timestamp = row['Initial_Timestamp']\n",
    "            temp_chunk.append(sentence)\n",
    "            temp_token_count += sentence_tokens\n",
    "        else:\n",
    "            # Save the previous chunk before starting a new one\n",
    "            if temp_chunk:\n",
    "                merged_chunks.append({\n",
    "                    'Speaker': speaker,\n",
    "                    'Transcript': \" \".join(temp_chunk),\n",
    "                    'Initial_Timestamp' : initial_timestamp,\n",
    "                    'Current_Timestamp' : row['Current_Timestamp']\n",
    "                })\n",
    "\n",
    "            # Start a new chunk with the current sentence\n",
    "            temp_chunk = [sentence]\n",
    "            temp_token_count = sentence_tokens\n",
    "            speaker = row['Speaker']\n",
    "            initial_timestamp = row['Initial_Timestamp']\n",
    "            final_timestamp = row['Current_Timestamp']\n",
    "\n",
    "    # Save last chunk if any content remains\n",
    "    if temp_chunk:\n",
    "        merged_chunks.append({\n",
    "            'Speaker': speaker,\n",
    "            'Transcript': \" \".join(temp_chunk),\n",
    "            'Initial_Timestamp' : initial_timestamp,\n",
    "            'Current_Timestamp' : final_timestamp\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    final_merged_df = pd.DataFrame(merged_chunks)\n",
    "    \n",
    "    return final_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c273c4fc-b034-44fc-b754-24df59b30995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f908c816554420695a05be97a785c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "\n",
    "model_path = \"models/meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    quantization_config=quantization_config,\n",
    "    trust_remote_code=True  # Add this for some custom models\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "metadata_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9688527d-162f-44db-a7d1-3b8550ddbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_metadate(metadata_pipeline, chunks: pd.DataFrame, metadata_schema: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract metadata from multiple chunks of a transcript using the specified model.\n",
    "\n",
    "    Args:\n",
    "        client: The AI client object.\n",
    "        model_name: The AI model to use.\n",
    "        chunks: A DataFrame with 'Speaker' and 'Transcript' columns.\n",
    "        metadata_schema: A dictionary representing the metadata schema.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A structured DataFrame containing extracted metadata.\n",
    "    \"\"\"\n",
    "    all_metadata = []\n",
    "\n",
    "    if isinstance(metadata_schema, str):\n",
    "        try:\n",
    "            with open(metadata_schema, \"r\", encoding=\"utf-8\") as f:\n",
    "                metadata_schema = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading metadata schema: {e}\")\n",
    "            return pd.DataFrame()\n",
    "                \n",
    "    schema_json = json.dumps(metadata_schema, indent=2)\n",
    "\n",
    "    for i, row in chunks.iloc[:4].iterrows():\n",
    "        speaker = row[\"Speaker\"]\n",
    "        transcript = row[\"Transcript\"]  # Prevent AI truncation\n",
    "        timestamp = row['Timestamp']\n",
    "\n",
    "\n",
    "\n",
    "          # JSON-structured prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are an AI model specialized in extracting structured metadata from interview transcripts.  \n",
    "        Return **only a valid JSON object** based on the given schema.  \n",
    "        If information is missing, set the value to `???`.  \n",
    "        For each extracted value, append the corresponding timestamp in parentheses (e.g., `Value (timestamp)`).  \n",
    "        If the value is `???`, do not append the timestamp.  \n",
    "        Do not add explanations, markdown formatting, or extra text.\n",
    "\n",
    "        Erforderliches Format:\n",
    "        {schema_json}\n",
    "\n",
    "        Transkript:\n",
    "        {transcript}\n",
    "\n",
    "        Timestamp:\n",
    "        {timestamp}\n",
    "\n",
    "        JSON-Antwort:\n",
    "        \"\"\"\n",
    "\n",
    "         # Generate response using the local LLaMA model\n",
    "        try:\n",
    "            response_text =  metadata_pipeline(prompt, max_new_tokens=1800,return_full_text=False,temperature=0.2)[0][\"generated_text\"]\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error generating response for chunk {i+1}: {e}\")\n",
    "            response_text = \"[]\"  # Default to an empty JSON\n",
    "        \n",
    "        # Debugging: Print the raw AI response to identify issues\n",
    "        print(f\"\\n🔍 DEBUG: Raw AI Response for chunk {i+1} data type {type(response_text)}:\\n{response_text}\\n\")\n",
    "\n",
    "        response_text = response_text.strip().strip(\"[]\")\n",
    "\n",
    "        # Extract the dictionary (remove list brackets)\n",
    "        # data_dict = data_list[0] if data_list else {}\n",
    "\n",
    "\n",
    "        metadata = response_text\n",
    "        # print(f\"\\n🔍 DEBUG: Raw Metadata for chunk {i+1}:{type(metadata)}\")\n",
    "        # Parse metadata into a dictionary\n",
    "        extracted_metadata = {\"Speaker\": speaker}  # Store speaker info\n",
    "        for line in metadata.split(\"\\n\"):\n",
    "            if \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                extracted_metadata[key.strip()] = value.strip()\n",
    "\n",
    "        # Remove \"%%%%\" values before storing\n",
    "        extracted_metadata = {k: (v.replace('\"', \"\") if v.replace('\"', \"\").replace(\",\", \"\") != \"???\" else \"\") for k, v in extracted_metadata.items()}\n",
    "\n",
    "        if i < 4 - 1:  # If not the last iteration\n",
    "            extracted_metadata = {k: v.strip() + \",\" if v else v.strip() for k, v in extracted_metadata.items()}\n",
    "\n",
    "        # Append metadata for this chunk\n",
    "        all_metadata.append(extracted_metadata)\n",
    "\n",
    "    # Convert metadata list into a DataFrame\n",
    "    return pd.DataFrame(all_metadata)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b71d5996-9701-4795-8974-2998e38a376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_transcript_optimized_with_timestamps(input_data: pd.DataFrame, model_name: str, max_tokens: int = 12000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Optimized chunking for LLaMA while preserving timestamps and minimizing chunk sizes.\n",
    "\n",
    "    Args:\n",
    "        input_data (pd.DataFrame): DataFrame containing 'Sprecher', 'Transkript', and 'Timecode'.\n",
    "        model_name (str): Name of the LLaMA model to determine the tokenizer.\n",
    "        max_tokens (int): Max tokens per chunk (default ~12,000).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Chunked transcript with timestamps and speakers.\n",
    "    \"\"\"\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Ensure 'Transkript' column has no NaN values\n",
    "    input_data['Transkript'] = input_data['Transkript'].fillna(\"\").astype(str)\n",
    "    \n",
    "    chunked_data = []\n",
    "    tokenized_text = []\n",
    "    token_timestamps = []\n",
    "    token_speakers = []\n",
    "    \n",
    "    for index, row in input_data.iterrows():\n",
    "        transcript = row['Transkript']\n",
    "        timestamp = row['Timecode']\n",
    "        speaker = row['Sprecher']\n",
    "        \n",
    "        tokenized_segment = tokenizer(transcript, return_tensors=\"pt\", truncation=False)[\"input_ids\"].squeeze().tolist()\n",
    "        tokenized_segment = tokenized_segment if isinstance(tokenized_segment, list) else [tokenized_segment]\n",
    "        \n",
    "        tokenized_text.extend(tokenized_segment)\n",
    "        token_timestamps.extend([timestamp] * len(tokenized_segment))  # Align timestamps with tokens\n",
    "        token_speakers.extend([speaker] * len(tokenized_segment))  # Align speakers with tokens\n",
    "    \n",
    "    start_idx = 0\n",
    "    while start_idx < len(tokenized_text):\n",
    "        # Get the next chunk within token limit\n",
    "        end_idx = min(start_idx + max_tokens, len(tokenized_text))\n",
    "        # Find the nearest sentence boundary\n",
    "        sub_text = tokenizer.decode(tokenized_text[start_idx:end_idx])\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', sub_text)  # Split at sentence boundaries\n",
    " \n",
    "        # Ensure the last sentence doesn't get cut off\n",
    "        chunk = \" \".join(sentences[:-1]) if len(sentences) > 1 else sub_text\n",
    "        \n",
    "        # Determine timestamps and speakers safely\n",
    "        initial_timestamp = token_timestamps[start_idx] if start_idx < len(token_timestamps) else None\n",
    "        current_timestamp = token_timestamps[end_idx - 1] if (end_idx - 1) < len(token_timestamps) else initial_timestamp\n",
    "        speaker = token_speakers[start_idx] if start_idx < len(token_speakers) else None\n",
    "        \n",
    "        # Store chunk details\n",
    "        chunked_data.append({\n",
    "            'Speaker': speaker,\n",
    "            'Transcript': chunk.strip(),\n",
    "            'Initial_Timestamp': initial_timestamp,\n",
    "            'Current_Timestamp': current_timestamp\n",
    "        })\n",
    "        \n",
    "        # Move start index past processed text\n",
    "        start_idx += len(tokenizer(chunk)[\"input_ids\"][0])\n",
    "    \n",
    "    return pd.DataFrame(chunked_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c74d92e9-7610-4094-b8f2-43838595c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: adg0001_er_2024_10_31.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m input_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# speaker_chunks_df = chunk_transcript(input_data)  # Stores speaker-based chunks\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# final_chunks_df = chunk_by_sentence(speaker_chunks_df)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m final_chunks_df \u001b[38;5;241m=\u001b[39m \u001b[43mchunk_transcript_optimized_with_timestamps\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m final_chunks_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m final_chunks_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial_Timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m final_chunks_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent_Timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[1;32m     23\u001b[0m final_chunks_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial_Timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent_Timestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[15], line 61\u001b[0m, in \u001b[0;36mchunk_transcript_optimized_with_timestamps\u001b[0;34m(input_data, model_name, max_tokens)\u001b[0m\n\u001b[1;32m     53\u001b[0m     chunked_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpeaker\u001b[39m\u001b[38;5;124m'\u001b[39m: speaker,\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTranscript\u001b[39m\u001b[38;5;124m'\u001b[39m: chunk\u001b[38;5;241m.\u001b[39mstrip(),\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial_Timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: initial_timestamp,\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent_Timestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: current_timestamp\n\u001b[1;32m     58\u001b[0m     })\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# Move start index past processed text\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     start_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokenizer(chunk)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(chunked_data)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "folder_path = \"Transcripts\"\n",
    "schema_file = \"metadata_schema.json\" \n",
    "# Load schema as dictionary\n",
    "with open(schema_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata_schema = json.load(f) \n",
    "    \n",
    "MODEL = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "# List to store metadata for all files\n",
    "all_metadata = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path) & filename.endswith(\".csv\"):\n",
    "        print(f\"\\nProcessing file: {filename}\")\n",
    "        input_data = pd.read_csv(file_path, sep=None, engine='python')\n",
    "        # speaker_chunks_df = chunk_transcript(input_data)  # Stores speaker-based chunks\n",
    "        # final_chunks_df = chunk_by_sentence(speaker_chunks_df)\n",
    "        final_chunks_df = chunk_transcript_optimized_with_timestamps(input_data , model_path)\n",
    "        final_chunks_df['Timestamp'] = final_chunks_df['Initial_Timestamp'] + \" - \" + final_chunks_df['Current_Timestamp'] \n",
    "        final_chunks_df.drop(columns=['Initial_Timestamp', \"Current_Timestamp\"], inplace=True)\n",
    "        # print(final_chunks_df)\n",
    "        \n",
    "\n",
    "        # Extract metadata for the chunks\n",
    "        llama_70b_responses = extract_metadate(metadata_pipeline, final_chunks_df, metadata_schema)\n",
    "        # Ensure that the response DataFrame contains metadata columns\n",
    "        if not llama_70b_responses.empty:\n",
    "            # Merge chunk outputs into a single row \n",
    "            merged_metadata = llama_70b_responses.apply(lambda col: ' '.join(col.dropna().astype(str)))\n",
    "            \n",
    "            for column in merged_metadata.index:\n",
    "                unique_values = set([value.strip() for value in merged_metadata[column].strip().split(\",\")])\n",
    "                list_unique_values = list(filter(None, unique_values))\n",
    "                merged_metadata[column] = \" | \".join(list_unique_values)\n",
    "\n",
    "            # Add filename for reference\n",
    "            # merged_metadata[\"Filename\"] = filename  \n",
    "\n",
    "            # Append to list\n",
    "            all_metadata.append(merged_metadata)\n",
    "        else:\n",
    "            print(f\"No metadata extracted from {filename}\")\n",
    "         \n",
    "        time.sleep(0.5)\n",
    "\n",
    "# Convert list of metadata rows into a single DataFrame\n",
    "final_metadata_df = pd.DataFrame(all_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f2d0cff3-937a-4f1b-a1bd-08dc6ac37c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>\"Standort\"</th>\n",
       "      <th>\"Archiv ID\"</th>\n",
       "      <th>\"PROBANDNR\"</th>\n",
       "      <th>\"DOK_ART\"</th>\n",
       "      <th>\"ARCHIVORT\"</th>\n",
       "      <th>\"PROVENIENZ\"</th>\n",
       "      <th>\"SPERRUNG\"</th>\n",
       "      <th>\"ENTSTZEIT\"</th>\n",
       "      <th>\"Zeitumfang 1\"</th>\n",
       "      <th>...</th>\n",
       "      <th>\"PART_HERKU\"</th>\n",
       "      <th>\"PART_SCHUL\"</th>\n",
       "      <th>\"PART_AUSBI\"</th>\n",
       "      <th>\"PART_STAND\"</th>\n",
       "      <th>\"PART_BERUF\"</th>\n",
       "      <th>\"PART_POLOR\"</th>\n",
       "      <th>\"PART_PKONV\"</th>\n",
       "      <th>\"PART_ENGAG\"</th>\n",
       "      <th>\"KRIT10\"</th>\n",
       "      <th>\"GRÜNDE\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INT_AH | IP_FA</td>\n",
       "      <td>Hemer im Sauerland</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Speaker          \"Standort\" \"Archiv ID\" \"PROBANDNR\" \"DOK_ART\"  \\\n",
       "0  INT_AH | IP_FA  Hemer im Sauerland                                     \n",
       "\n",
       "  \"ARCHIVORT\" \"PROVENIENZ\" \"SPERRUNG\" \"ENTSTZEIT\" \"Zeitumfang 1\"  ...  \\\n",
       "0                                                                 ...   \n",
       "\n",
       "  \"PART_HERKU\" \"PART_SCHUL\" \"PART_AUSBI\" \"PART_STAND\" \"PART_BERUF\"  \\\n",
       "0                                                                    \n",
       "\n",
       "  \"PART_POLOR\" \"PART_PKONV\" \"PART_ENGAG\" \"KRIT10\" \"GRÜNDE\"  \n",
       "0                                                           \n",
       "\n",
       "[1 rows x 138 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f51700bf-d9e9-442b-b72f-2e7c6f63af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metadata_df.to_csv(\"metadata_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de03740-0627-4509-ae6f-ebee01a6901a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
