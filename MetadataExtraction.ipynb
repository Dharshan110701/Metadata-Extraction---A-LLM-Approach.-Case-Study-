{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b07d9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Harshita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPORT STATEMENTS\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bbd677",
   "metadata": {},
   "source": [
    "## Metadata Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1244c",
   "metadata": {},
   "source": [
    "### Structure of Metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5cc9049c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standort</th>\n",
       "      <th>Archiv ID</th>\n",
       "      <th>PROBANDNR</th>\n",
       "      <th>DOK_ART</th>\n",
       "      <th>ARCHIVORT</th>\n",
       "      <th>PROVENIENZ</th>\n",
       "      <th>SPERRUNG</th>\n",
       "      <th>ENTSTZEIT</th>\n",
       "      <th>Zeitumfang 1</th>\n",
       "      <th>NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>PART_KONFESSION</th>\n",
       "      <th>PART_HERKU</th>\n",
       "      <th>PART_SCHUL</th>\n",
       "      <th>PART_AUSBI</th>\n",
       "      <th>PART_STAND</th>\n",
       "      <th>PART_BERUF</th>\n",
       "      <th>PART_POLOR</th>\n",
       "      <th>PART_PKONV</th>\n",
       "      <th>PART_ENGAG</th>\n",
       "      <th>KRIT10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IGNORE</td>\n",
       "      <td>IGNORE</td>\n",
       "      <td>IGNORE</td>\n",
       "      <td>IGNORE</td>\n",
       "      <td>IGNORE</td>\n",
       "      <td>IGNORE</td>\n",
       "      <td>IGNORE</td>\n",
       "      <td>IGNORE</td>\n",
       "      <td>IGNORE</td>\n",
       "      <td>IGNORE</td>\n",
       "      <td>...</td>\n",
       "      <td>confession life partner</td>\n",
       "      <td>place of birth life partner</td>\n",
       "      <td>school graduation life partner</td>\n",
       "      <td>apprenticeship/training life partner</td>\n",
       "      <td>social status life partner</td>\n",
       "      <td>profession life partner</td>\n",
       "      <td>political attitude life partner</td>\n",
       "      <td>change of political attitude life partner</td>\n",
       "      <td>social commitment life partner</td>\n",
       "      <td>IGNORE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Standort Archiv ID PROBANDNR DOK_ART ARCHIVORT PROVENIENZ SPERRUNG  \\\n",
       "0   IGNORE    IGNORE    IGNORE  IGNORE    IGNORE     IGNORE   IGNORE   \n",
       "\n",
       "  ENTSTZEIT Zeitumfang 1    NAME  ...          PART_KONFESSION  \\\n",
       "0    IGNORE       IGNORE  IGNORE  ...  confession life partner   \n",
       "\n",
       "                    PART_HERKU                      PART_SCHUL  \\\n",
       "0  place of birth life partner  school graduation life partner   \n",
       "\n",
       "                             PART_AUSBI                  PART_STAND  \\\n",
       "0  apprenticeship/training life partner  social status life partner   \n",
       "\n",
       "                PART_BERUF                       PART_POLOR  \\\n",
       "0  profession life partner  political attitude life partner   \n",
       "\n",
       "                                  PART_PKONV                      PART_ENGAG  \\\n",
       "0  change of political attitude life partner  social commitment life partner   \n",
       "\n",
       "   KRIT10  \n",
       "0  IGNORE  \n",
       "\n",
       "[1 rows x 136 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata schema CSV\n",
    "schema_file = r\"C:\\Users\\Harshita\\Downloads\\Metadata Scheme ADG.csv\"\n",
    "metadata_schema = pd.read_csv(schema_file,delimiter=\"\\t\" )\n",
    "metadata_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "439b1fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ DataFrame Successfully Converted to JSON!\n",
      "\n",
      "✅ Converted JSON Data:\n",
      "[\n",
      "    {\n",
      "        \"Standort\":\"IGNORE\",\n",
      "        \"Archiv ID\":\"IGNORE\",\n",
      "        \"PROBANDNR\":\"IGNORE\",\n",
      "        \"DOK_ART\":\"IGNORE\",\n",
      "        \"ARCHIVORT\":\"IGNORE\",\n",
      "        \"PROVENIENZ\":\"IGNORE\",\n",
      "        \"SPERRUNG\":\"IGNORE\",\n",
      "        \"ENTSTZEIT\":\"IGNORE\",\n",
      "        \"Zeitumfang 1\":\"IGNORE\",\n",
      "        \"NAME\":\"IGNORE\",\n",
      "        \"VORNAME\":\"IGNORE\",\n",
      "        \"ORT\":\"place of living\",\n",
      "        \"Feld1\":\"IGNORE\",\n",
      "        \"PSEUDONYM\":\"IGNORE\",\n",
      "        \"GESCHLECHT\":\"GENDER\",\n",
      "        \"JAHRGANG\":\"year of birth\",\n",
      "        \"IPV\":\"IGNORE\",\n",
      "        \"DATENBOGEN\":\"IGNORE\",\n",
      "        \"KURZBESCHR\":\"IGNORE\",\n",
      "        \"TITEL\":\"IGNORE\",\n",
      "        \"STRASSE\":\"IGNORE\",\n",
      "        \"PLZ\":\"IGNORE\",\n",
      "        \"TELEFON\":\"IGNORE\",\n",
      "        \"GRUPPE\":\"IGNORE\",\n",
      "        \"BERUF\":\"profession\",\n",
      "        \"HEUT_FAMST\":\"recent civil status\",\n",
      "        \"INTERVIEWE\":\"IGNORE\",\n",
      "        \"TIPPER\":\"IGNORE\",\n",
      "        \"Segmentierung\":\"IGNORE\",\n",
      "        \"DATUM1\":\"IGNORE\",\n",
      "        \"DATUM2\":\"IGNORE\",\n",
      "        \"DATUM3\":\"IGNORE\",\n",
      "        \"DAUER\":\"IGNORE\",\n",
      "        \"online\":\"IGNORE\",\n",
      "        \"AUSDRUCKSART\":\"IGNORE\",\n",
      "        \"UNKAUSDRUC\":\"IGNORE\",\n",
      "        \"KORRAUSDRU\":\"IGNORE\",\n",
      "        \"SCHLAGWORT\":\"IGNORE\",\n",
      "        \"KURZBIOGRA\":\"IGNORE\",\n",
      "        \"KURZPROTOK\":\"IGNORE\",\n",
      "        \"FOTOS\":\"IGNORE\",\n",
      "        \"DOKUMENTE\":\"IGNORE\",\n",
      "        \"VHS\":\"IGNORE\",\n",
      "        \"DVD\":\"IGNORE\",\n",
      "        \"IBM Server\":\"IGNORE\",\n",
      "        \"Cloud\":\"IGNORE\",\n",
      "        \"Format Cloud\":\"IGNORE\",\n",
      "        \"DV\":\"IGNORE\",\n",
      "        \"Beta\":\"IGNORE\",\n",
      "        \"ORIGCASSET\":\"IGNORE\",\n",
      "        \"CASSKOPIEN\":\"IGNORE\",\n",
      "        \"FESTPLATTE\":\"IGNORE\",\n",
      "        \"Dig Audiofiles\":\"IGNORE\",\n",
      "        \"KONF_HEUTE\":\"recent confession\",\n",
      "        \"KONVERSION\":\"change of religion\",\n",
      "        \"WANN_KONV\":\"date change of religion\",\n",
      "        \"HERKUNFT\":\"place of birth\",\n",
      "        \"WANN_ZUGEZ\":\"date migration\",\n",
      "        \"GESCHWISTE\":\"siblings\",\n",
      "        \"Schulabsch\":\"graduation (school)\",\n",
      "        \"ABGEBROCHE\":\"date if dropped out of  school \",\n",
      "        \"WEITERBILD\":\"further education\",\n",
      "        \"AUSBILDUNG\":\"apprenticeship\\/training\",\n",
      "        \"STAND\":\"recent job status\",\n",
      "        \"WIRTSCHBER\":\"business sector of recent job\",\n",
      "        \"BERUFSWECH\":\"change of profession\",\n",
      "        \"WANN_WECHS\":\"date if profession has been changed\",\n",
      "        \"AUFABSTIEG\":\"IGNORE\",\n",
      "        \"BERUFSBEGI\":\"date first job\",\n",
      "        \"BERUFSENDE\":\"retirement\",\n",
      "        \"NICHTERWER\":\"Non-activity (like parental leave or maternal protection \\u2013 not unemployment!)\",\n",
      "        \"GR\\u00dcNDE\":\"reasons for non-activity\",\n",
      "        \"VON_BIS\":\"time span non-activity\",\n",
      "        \"ARBEITSLOS\":\"unemployment\",\n",
      "        \"VON_BIS_AL\":\"time span unemployment\",\n",
      "        \"FAM_STAND\":\"civil status\",\n",
      "        \"HEIRAT1JHR\":\"1st marriage\",\n",
      "        \"HEIRAT2JHR\":\"2nd marriage\",\n",
      "        \"HEIRAT3JHR\":\"3rd marriage\",\n",
      "        \"SCHEID1JHR\":\"1st divorce\",\n",
      "        \"SCHEID2JHR\":\"2nd divorce\",\n",
      "        \"VERWIT1JHR\":\"date 1st widowhood\",\n",
      "        \"VERWIT2JHR\":\"date 2nd widowhood\",\n",
      "        \"KINDERZAHL\":\"number of children\",\n",
      "        \"GEB_JAHR1\":\"date of birth child 1\",\n",
      "        \"GEB_JAHR2\":\"date of birth child 1\",\n",
      "        \"GEB_JAHR_L\":\"date of birth last child\",\n",
      "        \"AUFABKIND\":\"IGNORE\",\n",
      "        \"POLOR_HEUT\":\"recent political attitude\",\n",
      "        \"POL_KONVER\":\"change of political attitude\",\n",
      "        \"POLORIENT1\":\"1st political attitude\",\n",
      "        \"VON_BIS_1\":\"time span 1st political attitude\",\n",
      "        \"POLORIENT2\":\"2nd political attitude\",\n",
      "        \"VON_BIS_2\":\"time span 2nd political attitude\",\n",
      "        \"GEW_VERBAN\":\"membership in union\",\n",
      "        \"VON_BIS_GV\":\"time span membership in union\",\n",
      "        \"JUGENDORG1\":\"1st membership in youth organization\",\n",
      "        \"VON_BIS_J1\":\"time span 1st membership in youth organization\",\n",
      "        \"JUGENDORG2\":\"2nd membership in youth organization\",\n",
      "        \"VON_BIS_J2\":\"time span 2nd membership in youth organization\",\n",
      "        \"NS_ORGAN_1\":\"1st membership in NS-organization\",\n",
      "        \"VON_BISNS1\":\"time span 1st membership in NS-organization\",\n",
      "        \"NS_ORGAN_2\":\"2nd membership in NS-organization\",\n",
      "        \"VON_BISNS2\":\"time span 2nd membership in NS-organization\",\n",
      "        \"RAD_KLV_DV\":\"Experienced Reichsarbeitsdienst, Kinderlandverschickung or Dienstverpflichtung? \",\n",
      "        \"VON_BISRAD\":\"time span experience of Reichsarbeitsdienst, Kinderlandverschickung or Dienstverpflichtung \",\n",
      "        \"SONST_ENG\":\"further social commitment\",\n",
      "        \"VON_BIS_SE\":\"time span further social commitment\",\n",
      "        \"KRIEGSTEIL\":\"war experience\",\n",
      "        \"VON_BIS_KR\":\"time span war experience\",\n",
      "        \"BES_BERICH\":\"IGNORE\",\n",
      "        \"MUTT_JG\":\"year of birth mother\",\n",
      "        \"MUTT_KONFESSION\":\"confession mother\",\n",
      "        \"MUTT_HERKU\":\"place of birth mother\",\n",
      "        \"MUTT_SCHUL\":\"school graduation mother\",\n",
      "        \"MUTT_AUSBI\":\"apprenticeship\\/training mother\",\n",
      "        \"MUTT_STAND\":\"social status mother\",\n",
      "        \"MUTT_POLOR\":\"political attitude mother\",\n",
      "        \"VAT_JG\":\"year of birth father\",\n",
      "        \"VAT_KONFESSION\":\"confession father\",\n",
      "        \"VAT_HERKUN\":\"place of birth father\",\n",
      "        \"VAT_SCHULE\":\"school graduation father\",\n",
      "        \"VAT_AUSBIL\":\"apprenticeship\\/training father\",\n",
      "        \"VAT_STAND\":\"social status father\",\n",
      "        \"VAT_POLOR\":\"political attitude father\",\n",
      "        \"PART_JG\":\"year of birth life partner\",\n",
      "        \"PART_KONFESSION\":\"confession life partner\",\n",
      "        \"PART_HERKU\":\"place of birth life partner\",\n",
      "        \"PART_SCHUL\":\"school graduation life partner\",\n",
      "        \"PART_AUSBI\":\"apprenticeship\\/training life partner\",\n",
      "        \"PART_STAND\":\"social status life partner\",\n",
      "        \"PART_BERUF\":\"profession life partner\",\n",
      "        \"PART_POLOR\":\"political attitude life partner\",\n",
      "        \"PART_PKONV\":\"change of political attitude life partner\",\n",
      "        \"PART_ENGAG\":\"social commitment life partner\",\n",
      "        \"KRIT10\":\"IGNORE\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def convert_dataframe_to_json(df, output_json):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame into a structured JSON format.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the metadata schema.\n",
    "        output_json (str): Path to save the output JSON file.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string representation of the DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert DataFrame to JSON\n",
    "        json_data = df.to_json(orient=\"records\", indent=4)\n",
    "\n",
    "        # Save JSON to file\n",
    "        with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(json_data)\n",
    "\n",
    "        print(\"\\n✅ DataFrame Successfully Converted to JSON!\")\n",
    "        return json_data  # Return JSON string for verification\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error converting DataFrame to JSON: {e}\")\n",
    "        return \"{}\"  # Return empty JSON if error occurs\n",
    "\n",
    "# Example usage\n",
    "output_json = r\"C:\\Users\\Harshita\\Downloads\\case study\\metadata_schema.json\"\n",
    "\n",
    "# Convert DataFrame to JSON\n",
    "metadata_schema_json = convert_dataframe_to_json(metadata_schema, output_json)\n",
    "\n",
    "# Print JSON output\n",
    "print(\"\\n✅ Converted JSON Data:\")\n",
    "print(metadata_schema_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb2516",
   "metadata": {},
   "source": [
    "### The Metadata has 136 columns to be filled "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482bf8e1",
   "metadata": {},
   "source": [
    "### Loading the transcipts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac85ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_interview_csvs(folder_path):\n",
    "    \"\"\"\n",
    "    Loads all interview CSV files from the specified folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the directory containing interview CSV files.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are filenames and values are DataFrames.\n",
    "    \"\"\"\n",
    "    interview_data = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Check if it's a valid CSV file\n",
    "        if os.path.isfile(file_path) and filename.endswith(\".csv\"):\n",
    "            print(f\"\\n📂 Loading interview file: {filename}\")\n",
    "            try:\n",
    "                input_data = pd.read_csv(file_path, sep=None, engine='python')\n",
    "                interview_data[filename] = input_data\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error loading {filename}: {e}\")\n",
    "\n",
    "    return interview_data\n",
    "\n",
    "# # Example usage:\n",
    "# folder_path = r\"C:\\Users\\Harshita\\Downloads\\case study\\Transcripts\"\n",
    "# interview_csvs = load_interview_csvs(folder_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117af91",
   "metadata": {},
   "source": [
    "### Transcript Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa64185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_transcript(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # Ensure 'Transkript' column has no NaN values\n",
    "    data['Transkript'] = data['Transkript'].fillna(\"\").astype(str)\n",
    "\n",
    "    # Chunking logic\n",
    "    chunked_data = []\n",
    "    current_speaker = None\n",
    "    current_text = \"\"\n",
    "    initial_timestamp = \"\"\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        speaker = row['Sprecher']\n",
    "        transcript = row['Transkript']\n",
    "        timestamp = row['Timecode'] \n",
    "\n",
    "        if speaker != current_speaker:\n",
    "            # Save previous chunk if exists\n",
    "            if current_speaker is not None:\n",
    "                chunked_data.append({\n",
    "                    'Speaker': current_speaker,\n",
    "                    'Transcript': current_text.strip(),\n",
    "                    'Initial_Timestamp' : initial_timestamp,\n",
    "                    'Current_Timestamp' : timestamp\n",
    "                })\n",
    "            \n",
    "            # Start a new chunk\n",
    "            current_speaker = speaker\n",
    "            current_text = transcript\n",
    "            initial_timestamp = timestamp \n",
    "        else:\n",
    "            # Continue appending to the same speaker's chunk\n",
    "            current_text += \" \" + transcript if isinstance(transcript, str) else \"\"\n",
    "\n",
    "    # Save the last chunk\n",
    "    if current_speaker is not None:\n",
    "        chunked_data.append({\n",
    "            'Speaker': current_speaker,\n",
    "            'Transcript': current_text.strip(),\n",
    "            'Initial_Timestamp' : initial_timestamp,\n",
    "            'Current_Timestamp' : timestamp\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    chunked_df = pd.DataFrame(chunked_data)\n",
    "    \n",
    "    return chunked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4989bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_sentence(chunked_df: pd.DataFrame, min_tokens=256, max_tokens=512) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Further splits chunks by sentence while ensuring each chunk is within a token range.\n",
    "\n",
    "    Args:\n",
    "        chunked_df (pd.DataFrame): Input DataFrame with 'Speaker' and 'Transcript' columns.\n",
    "        min_tokens (int): Minimum number of tokens per chunk.\n",
    "        max_tokens (int): Maximum number of tokens per chunk.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with sentence-based chunked transcripts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Function to count tokens (approximate, assuming 1 word ≈ 1.2 tokens)\n",
    "    def count_tokens(text):\n",
    "        return len(text.split()) * 1.2  # Rough estimate\n",
    "\n",
    "    # Initialize list for final merged chunks\n",
    "    merged_chunks = []\n",
    "    temp_chunk = []\n",
    "    temp_token_count = 0\n",
    "    speaker = None\n",
    "    initial_timestamp = \"\"\n",
    "    final_timestamp = \"\"\n",
    "\n",
    "    # Process each row\n",
    "    for _, row in chunked_df.iterrows():\n",
    "        sentence = row['Transcript']\n",
    "        sentence_tokens = count_tokens(sentence)\n",
    "\n",
    "        # If adding this chunk keeps us within MAX_TOKENS\n",
    "        if temp_token_count + sentence_tokens <= max_tokens:\n",
    "            if not temp_chunk:\n",
    "                speaker = row['Speaker']  # Store speaker only for new chunks\n",
    "                initial_timestamp = row['Initial_Timestamp']\n",
    "            temp_chunk.append(sentence)\n",
    "            temp_token_count += sentence_tokens\n",
    "        else:\n",
    "            # Save the previous chunk before starting a new one\n",
    "            if temp_chunk:\n",
    "                merged_chunks.append({\n",
    "                    'Speaker': speaker,\n",
    "                    'Transcript': \" \".join(temp_chunk),\n",
    "                    'Initial_Timestamp' : initial_timestamp,\n",
    "                    'Current_Timestamp' : row['Current_Timestamp']\n",
    "                })\n",
    "\n",
    "            # Start a new chunk with the current sentence\n",
    "            temp_chunk = [sentence]\n",
    "            temp_token_count = sentence_tokens\n",
    "            speaker = row['Speaker']\n",
    "            initial_timestamp = row['Initial_Timestamp']\n",
    "            final_timestamp = row['Current_Timestamp']\n",
    "\n",
    "    # Save last chunk if any content remains\n",
    "    if temp_chunk:\n",
    "        merged_chunks.append({\n",
    "            'Speaker': speaker,\n",
    "            'Transcript': \" \".join(temp_chunk),\n",
    "            'Initial_Timestamp' : initial_timestamp,\n",
    "            'Current_Timestamp' : final_timestamp\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    final_merged_df = pd.DataFrame(merged_chunks)\n",
    "    \n",
    "    return final_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d7b5fa",
   "metadata": {},
   "source": [
    "### Using Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "83ad18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq client initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# api_key = \"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\"\n",
    "# api_key = \"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\"\n",
    "api_key = \"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\"\n",
    "# api_key = \"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\"\n",
    "# api_key = \"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\"\n",
    "# api_key = \"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\"\n",
    "#Initialize the Groq client\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "print(\"Groq client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "93e91d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_metadata(client, model_name: str, chunks: pd.DataFrame, metadata_schema: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract metadata from multiple chunks of a German transcript using the specified model.\n",
    "\n",
    "    Args:\n",
    "        client: The Groq client object.\n",
    "        model_name: The AI model to use.\n",
    "        chunks: A DataFrame with 'Speaker' and 'Transcript' columns.\n",
    "        metadata_schema: A dictionary representing the metadata schema.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing structured extracted metadata.\n",
    "    \"\"\"\n",
    "    all_metadata = []\n",
    "\n",
    "    for i, row in chunks.iterrows():\n",
    "        speaker = row[\"Speaker\"]\n",
    "        transcript = row[\"Transcript\"][:1500]  # Prevent AI truncation\n",
    "        timestamp = row[\"Timestamp\"]\n",
    "\n",
    "        print(f\"Processing chunk {i+1}/{len(chunks)} for Speaker: {speaker}...\")\n",
    "\n",
    "        # Dynamically structure the JSON schema for the prompt\n",
    "        schema_json = json.dumps(metadata_schema, indent=2)\n",
    "\n",
    "        # JSON-structured prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are a highly skilled metadata extraction AI. Your task is to analyze the provided transcript \n",
    "        and extract structured metadata according to a predefined schema. The metadata schema contains field names and their descriptions.\n",
    "\n",
    "        **Your Task:**\n",
    "        1. Extract relevant metadata from the transcript while adhering **strictly** to the JSON schema.\n",
    "        2. Fields labeled `\"IGNORE\"` should **not be discarded**—instead, use the column name as its description.\n",
    "        3. If information is **missing** in the transcript,  set it to `\"???\"`.\n",
    "\n",
    "        **📌 Metadata Extraction Schema**\n",
    "        Extract metadata using the **following JSON schema**:\n",
    "\n",
    "        \n",
    "        {schema_json}\n",
    "       \n",
    "\n",
    "        **📌 Output Format**\n",
    "        Your response **must** be a **valid JSON object** following the schema, with no extra text.\n",
    "\n",
    "        ---\n",
    "        **📌 Transcript:**\n",
    "        {transcript}\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate response using the Groq client\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        # Extract raw response\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Debugging: Print the raw AI response to identify issues\n",
    "        print(f\"\\n🔍 DEBUG: Raw AI Response for chunk {i+1}:\\n{response_text}\\n\")\n",
    "\n",
    "        # **Fix Hidden JSON Formatting Issues**\n",
    "        response_text = response_text.strip(\"`\")  # Remove possible markdown backticks\n",
    "        response_text = re.sub(r'```json|```', '', response_text).strip()  # Remove ```json blocks\n",
    "\n",
    "        # Parse AI response to JSON\n",
    "        try:\n",
    "            metadata = json.loads(response_text)  # Convert response to JSON\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"❌ JSON Error in chunk {i+1}: {e}\\nAI Response:\\n{response_text}\\nSkipping this chunk...\")\n",
    "            continue\n",
    "\n",
    "        # Clean metadata: remove invalid values\n",
    "        extracted_metadata = {key: value if value not in [\"%%%\", None, \"\", \"null\"] else None for key, value in metadata.items()}\n",
    "        extracted_metadata[\"Speaker\"] = speaker\n",
    "        extracted_metadata[\"Timestamp\"] = timestamp\n",
    "\n",
    "        all_metadata.append(extracted_metadata)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(all_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8cefd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_metadate(client, model_name: str, chunks: pd.DataFrame, metadata_schema: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract metadata from multiple chunks of a transcript using the specified model.\n",
    "\n",
    "    Args:\n",
    "        client: The AI client object.\n",
    "        model_name: The AI model to use.\n",
    "        chunks: A DataFrame with 'Speaker' and 'Transcript' columns.\n",
    "        metadata_schema: A dictionary representing the metadata schema.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A structured DataFrame containing extracted metadata.\n",
    "    \"\"\"\n",
    "    all_metadata = []\n",
    "\n",
    "    for i, row in chunks.iterrows():\n",
    "        speaker = row[\"Speaker\"]\n",
    "        transcript = row[\"Transcript\"][:1500]  # Prevent AI truncation\n",
    "        timestamp = row[\"Timestamp\"]\n",
    "\n",
    "        # Convert schema to JSON format\n",
    "        schema_json = json.dumps(metadata_schema, indent=2)\n",
    "\n",
    "        \n",
    "          # JSON-structured prompt\n",
    "        prompt = f\"\"\"\n",
    "        Extrahieren Sie die folgenden Informationen aus dem Transkript und geben Sie die Antwort als **valide JSON-Struktur** zurück.\n",
    "        Falls eine Information nicht gefunden wird, setzen Sie den Wert als `null`.\n",
    "        Antwort **nur als JSON**, keine Erklärungen oder zusätzlichen Texte.\n",
    "\n",
    "        Geben Sie die Antwort exakt in folgendem Format:\n",
    "        {schema_json}\n",
    "\n",
    "        Antwort nur als JSON:\n",
    "\n",
    "        Transkript:\n",
    "        {transcript}\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate response using AI model\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "\n",
    "        # Extract raw response\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Debugging: Print the raw AI response to identify issues\n",
    "        print(f\"\\n🔍 DEBUG: Raw AI Response for chunk {i+1}:\\n{response_text}\\n\")\n",
    "\n",
    "        # **Fix Hidden JSON Formatting Issues**\n",
    "        response_text = response_text.strip(\"`\")  # Remove possible markdown backticks\n",
    "        response_text = re.sub(r'```json|```', '', response_text).strip()  # Remove ```json blocks\n",
    "\n",
    "        # Parse AI response to JSON\n",
    "        try:\n",
    "            metadata = json.loads(response_text)  # Convert response to JSON\n",
    "            if isinstance(metadata, list):  # If AI returned a list, take the first object\n",
    "                metadata = metadata[0]\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"❌ JSON Error in chunk {i+1}: {e}\\nAI Response:\\n{response_text}\\nSkipping this chunk...\")\n",
    "            metadata = {key: \"???\" for key in metadata_schema.keys()}  # Fill with `\"???\"`\n",
    "\n",
    "        # Clean metadata: remove invalid values\n",
    "        extracted_metadata = {key: value if value not in [\"%%%\", None, \"\", \"null\"] else None for key, value in metadata.items()}\n",
    "        extracted_metadata[\"Speaker\"] = speaker\n",
    "        extracted_metadata[\"Timestamp\"] = timestamp\n",
    "\n",
    "        all_metadata.append(extracted_metadata)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(all_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f123c413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00d4c4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: adg0001_er_2024_10_31.csv\n",
      "\n",
      "🔍 DEBUG: Raw AI Response for chunk 1:\n",
      "[\n",
      "  {\n",
      "    \"Standort\": null,\n",
      "    \"Archiv ID\": null,\n",
      "    \"PROBANDNR\": null,\n",
      "    \"DOK_ART\": null,\n",
      "    \"ARCHIVORT\": null,\n",
      "    \"PROVENIENZ\": null,\n",
      "    \"SPERRUNG\": null,\n",
      "    \"ENTSTZEIT\": null,\n",
      "    \"Zeitumfang 1\": null,\n",
      "    \"NAME\": null,\n",
      "    \"VORNAME\": null,\n",
      "    \"ORT\": \"Hemer im Sauerland\",\n",
      "    \"Feld1\": null,\n",
      "    \"PSEUDONYM\": null,\n",
      "    \"GESCHLECHT\": null,\n",
      "    \"JAHRGANG\": \"1925\",\n",
      "    \"IPV\": null,\n",
      "    \"DATENBOGEN\": null,\n",
      "    \"KURZBESCHR\": null,\n",
      "    \"TITEL\": null,\n",
      "    \"STRASSE\": null,\n",
      "    \"PLZ\": null,\n",
      "    \"TELEFON\": null,\n",
      "    \"GRUPPE\": null,\n",
      "    \"BERUF\": null,\n",
      "    \"HEUT_FAMST\": null,\n",
      "    \"INTERVIEWE\": null,\n",
      "    \"TIPPER\": null,\n",
      "    \"Segmentierung\": null,\n",
      "    \"DATUM1\": null,\n",
      "    \"DATUM2\": null,\n",
      "    \"DATUM3\": null,\n",
      "    \"DAUER\": null,\n",
      "    \"online\": null,\n",
      "    \"AUSDRUCKSART\": null,\n",
      "    \"UNKAUSDRUC\": null,\n",
      "    \"KORRAUSDRU\": null,\n",
      "    \"SCHLAGWORT\": null,\n",
      "    \"KURZBIOGRA\": null,\n",
      "    \"KURZPROTOK\": null,\n",
      "    \"FOTOS\": null,\n",
      "    \"DOKUMENTE\": null,\n",
      "    \"VHS\": null,\n",
      "    \"DVD\": null,\n",
      "    \"IBM Server\": null,\n",
      "    \"Cloud\": null,\n",
      "    \"Format Cloud\": null,\n",
      "    \"DV\": null,\n",
      "    \"Beta\": null,\n",
      "    \"ORIGCASSET\": null,\n",
      "    \"CASSKOPIEN\": null,\n",
      "    \"FESTPLATTE\": null,\n",
      "    \"Dig Audiofiles\": null,\n",
      "    \"KONF_HEUTE\": null,\n",
      "    \"KONVERSION\": null,\n",
      "    \"WANN_KONV\": null,\n",
      "    \"HERKUNFT\": \"Hemer im Sauerland\",\n",
      "    \"WANN_ZUGEZ\": null,\n",
      "    \"GESCHWISTE\": null,\n",
      "    \"Schulabsch\": \"Hauptschulabschluss 1939\",\n",
      "    \"ABGEBROCHE\": null,\n",
      "    \"WEITERBILD\": null,\n",
      "    \"AUSBILDUNG\": null,\n",
      "    \"STAND\": null,\n",
      "    \"WIRTSCHBER\": null,\n",
      "    \"BERUFSWECH\": null,\n",
      "    \"WANN_WECHS\": null,\n",
      "    \"AUFABSTIEG\": null,\n",
      "    \"BERUFSBEGI\": null,\n",
      "    \"BERUFSENDE\": null,\n",
      "    \"NICHTERWER\": null,\n",
      "    \"GRÜNDE\": null,\n",
      "    \"VON_BIS\": null,\n",
      "    \"ARBEITSLOS\": null,\n",
      "    \"VON_BIS_AL\": null,\n",
      "    \"FAM_STAND\": null,\n",
      "    \"HEIRAT1JHR\": null,\n",
      "    \"HEIRAT2JHR\": null,\n",
      "    \"HEIRAT3JHR\": null,\n",
      "    \"SCHEID1JHR\": null,\n",
      "    \"SCHEID2JHR\": null,\n",
      "    \"VERWIT1JHR\": null,\n",
      "    \"VERWIT2JHR\": null,\n",
      "    \"KINDERZAHL\": null,\n",
      "    \"GEB_JAHR1\": null,\n",
      "    \"GEB_JAHR2\": null,\n",
      "    \"GEB_JAHR_L\": null,\n",
      "    \"AUFABKIND\": null,\n",
      "    \"POLOR_HEUT\": null,\n",
      "    \"POL_KONVER\": null,\n",
      "    \"POLORIENT1\": null,\n",
      "    \"VON_BIS_1\": null,\n",
      "    \"POLORIENT2\": null,\n",
      "    \"VON_BIS_2\": null,\n",
      "    \"GEW_VERBAN\": null,\n",
      "    \"VON_BIS_GV\": null,\n",
      "    \"JUGENDORG1\": null,\n",
      "    \"VON_BIS_J1\": null,\n",
      "    \"JUGENDORG2\": null,\n",
      "    \"VON_BIS_J2\": null,\n",
      "    \"NS_ORGAN_1\": null,\n",
      "    \"VON_BISNS1\": null,\n",
      "    \"NS_ORGAN_2\": null,\n",
      "    \"VON_BISNS2\": null,\n",
      "    \"RAD_KLV_DV\": null,\n",
      "    \"VON_BISRAD\": null,\n",
      "    \"SONST_ENG\": null,\n",
      "    \"VON_BIS_SE\": null,\n",
      "    \"KRIEGSTEIL\": null,\n",
      "    \"VON_BIS_KR\": null,\n",
      "    \"BES_BERICH\": null,\n",
      "    \"MUTT_JG\": null,\n",
      "    \"MUTT_KONFESSION\": null,\n",
      "    \"MUTT_HERKU\": null,\n",
      "    \"MUTT_SCHUL\": null,\n",
      "    \"MUTT_AUSBI\": null,\n",
      "    \"MUTT_STAND\": null,\n",
      "    \"MUTT_POLOR\": null,\n",
      "    \"VAT_JG\": null,\n",
      "    \"VAT_KONFESSION\": null,\n",
      "    \"VAT_HERKUN\": null,\n",
      "    \"VAT_SCHULE\": null,\n",
      "    \"VAT_AUSBIL\": null,\n",
      "    \"VAT_STAND\": null,\n",
      "    \"VAT_POLOR\": null,\n",
      "    \"PART_JG\": null,\n",
      "    \"PART_KONFESSION\": null,\n",
      "    \"PART_HERKU\": null,\n",
      "    \"PART_SCHUL\": null,\n",
      "    \"PART_AUSBI\": null,\n",
      "    \"PART_STAND\": null,\n",
      "    \"PART_BERUF\": null,\n",
      "    \"PART_POLOR\": null,\n",
      "    \"PART_PKONV\": null,\n",
      "    \"PART_ENGAG\": null,\n",
      "    \"KRIT10\": null\n",
      "  }\n",
      "]\n",
      "\n",
      "\n",
      "🔍 DEBUG: Raw AI Response for chunk 2:\n",
      "[\n",
      "  {\n",
      "    \"Standort\": null,\n",
      "    \"Archiv ID\": null,\n",
      "    \"PROBANDNR\": null,\n",
      "    \"DOK_ART\": null,\n",
      "    \"ARCHIVORT\": null,\n",
      "    \"PROVENIENZ\": null,\n",
      "    \"SPERRUNG\": null,\n",
      "    \"ENTSTZEIT\": null,\n",
      "    \"Zeitumfang 1\": null,\n",
      "    \"NAME\": null,\n",
      "    \"VORNAME\": null,\n",
      "    \"ORT\": null,\n",
      "    \"Feld1\": null,\n",
      "    \"PSEUDONYM\": null,\n",
      "    \"GESCHLECHT\": null,\n",
      "    \"JAHRGANG\": null,\n",
      "    \"IPV\": null,\n",
      "    \"DATENBOGEN\": null,\n",
      "    \"KURZBESCHR\": null,\n",
      "    \"TITEL\": null,\n",
      "    \"STRASSE\": null,\n",
      "    \"PLZ\": null,\n",
      "    \"TELEFON\": null,\n",
      "    \"GRUPPE\": null,\n",
      "    \"BERUF\": null,\n",
      "    \"HEUT_FAMST\": null,\n",
      "    \"INTERVIEWE\": null,\n",
      "    \"TIPPER\": null,\n",
      "    \"Segmentierung\": null,\n",
      "    \"DATUM1\": null,\n",
      "    \"DATUM2\": null,\n",
      "    \"DATUM3\": null,\n",
      "    \"DAUER\": null,\n",
      "    \"online\": null,\n",
      "    \"AUSDRUCKSART\": null,\n",
      "    \"UNKAUSDRUC\": null,\n",
      "    \"KORRAUSDRU\": null,\n",
      "    \"SCHLAGWORT\": null,\n",
      "    \"KURZBIOGRA\": null,\n",
      "    \"KURZPROTOK\": null,\n",
      "    \"FOTOS\": null,\n",
      "    \"DOKUMENTE\": null,\n",
      "    \"VHS\": null,\n",
      "    \"DVD\": null,\n",
      "    \"IBM Server\": null,\n",
      "    \"Cloud\": null,\n",
      "    \"Format Cloud\": null,\n",
      "    \"DV\": null,\n",
      "    \"Beta\": null,\n",
      "    \"ORIGCASSET\": null,\n",
      "    \"CASSKOPIEN\": null,\n",
      "    \"FESTPLATTE\": null,\n",
      "    \"Dig Audiofiles\": null,\n",
      "    \"KONF_HEUTE\": null,\n",
      "    \"KONVERSION\": null,\n",
      "    \"WANN_KONV\": null,\n",
      "    \"HERKUNFT\": null,\n",
      "    \"WANN_ZUGEZ\": null,\n",
      "    \"GESCHWISTE\": \"1 Schwester\",\n",
      "    \"Schulabsch\": null,\n",
      "    \"ABGEBROCHE\": null,\n",
      "    \"WEITERBILD\": null,\n",
      "    \"AUSBILDUNG\": null,\n",
      "    \"STAND\": null,\n",
      "    \"WIRTSCHBER\": null,\n",
      "    \"BERUFSWECH\": null,\n",
      "    \"WANN_WECHS\": null,\n",
      "    \"AUFABSTIEG\": null,\n",
      "    \"BERUFSBEGI\": null,\n",
      "    \"BERUFSENDE\": null,\n",
      "    \"NICHTERWER\": null,\n",
      "    \"GRÜNDE\": null,\n",
      "    \"VON_BIS\": null,\n",
      "    \"ARBEITSLOS\": null,\n",
      "    \"VON_BIS_AL\": null,\n",
      "    \"FAM_STAND\": null,\n",
      "    \"HEIRAT1JHR\": null,\n",
      "    \"HEIRAT2JHR\": null,\n",
      "    \"HEIRAT3JHR\": null,\n",
      "    \"SCHEID1JHR\": null,\n",
      "    \"SCHEID2JHR\": null,\n",
      "    \"VERWIT1JHR\": null,\n",
      "    \"VERWIT2JHR\": null,\n",
      "    \"KINDERZAHL\": \"1 Schwester\",\n",
      "    \"GEB_JAHR1\": null,\n",
      "    \"GEB_JAHR2\": null,\n",
      "    \"GEB_JAHR_L\": null,\n",
      "    \"AUFABKIND\": null,\n",
      "    \"POLOR_HEUT\": null,\n",
      "    \"POL_KONVER\": null,\n",
      "    \"POLORIENT1\": null,\n",
      "    \"VON_BIS_1\": null,\n",
      "    \"POLORIENT2\": null,\n",
      "    \"VON_BIS_2\": null,\n",
      "    \"GEW_VERBAN\": null,\n",
      "    \"VON_BIS_GV\": null,\n",
      "    \"JUGENDORG1\": null,\n",
      "    \"VON_BIS_J1\": null,\n",
      "    \"JUGENDORG2\": null,\n",
      "    \"VON_BIS_J2\": null,\n",
      "    \"NS_ORGAN_1\": null,\n",
      "    \"VON_BISNS1\": null,\n",
      "    \"NS_ORGAN_2\": null,\n",
      "    \"VON_BISNS2\": null,\n",
      "    \"RAD_KLV_DV\": null,\n",
      "    \"VON_BISRAD\": null,\n",
      "    \"SONST_ENG\": null,\n",
      "    \"VON_BIS_SE\": null,\n",
      "    \"KRIEGSTEIL\": null,\n",
      "    \"VON_BIS_KR\": null,\n",
      "    \"BES_BERICH\": null,\n",
      "    \"MUTT_JG\": null,\n",
      "    \"MUTT_KONFESSION\": null,\n",
      "    \"MUTT_HERKU\": null,\n",
      "    \"MUTT_SCHUL\": null,\n",
      "    \"MUTT_AUSBI\": null,\n",
      "    \"MUTT_STAND\": null,\n",
      "    \"MUTT_POLOR\": null,\n",
      "    \"VAT_JG\": null,\n",
      "    \"VAT_KONFESSION\": null,\n",
      "    \"VAT_HERKUN\": null,\n",
      "    \"VAT_SCHULE\": null,\n",
      "    \"VAT_AUSBIL\": null,\n",
      "    \"VAT_STAND\": null,\n",
      "    \"VAT_POLOR\": null,\n",
      "    \"PART_JG\": null,\n",
      "    \"PART_KONFESSION\": null,\n",
      "    \"PART_HERKU\": null,\n",
      "    \"PART_SCHUL\": null,\n",
      "    \"PART_AUSBI\": null,\n",
      "    \"PART_STAND\": null,\n",
      "    \"PART_BERUF\": null,\n",
      "    \"PART_POLOR\": null,\n",
      "    \"PART_PKONV\": null,\n",
      "    \"PART_ENGAG\": null,\n",
      "    \"KRIT10\": null\n",
      "  }\n",
      "]\n",
      "\n",
      "\n",
      "🔍 DEBUG: Raw AI Response for chunk 3:\n",
      "[\n",
      "  {\n",
      "    \"Standort\": null,\n",
      "    \"Archiv ID\": null,\n",
      "    \"PROBANDNR\": null,\n",
      "    \"DOK_ART\": null,\n",
      "    \"ARCHIVORT\": null,\n",
      "    \"PROVENIENZ\": null,\n",
      "    \"SPERRUNG\": null,\n",
      "    \"ENTSTZEIT\": null,\n",
      "    \"Zeitumfang 1\": null,\n",
      "    \"NAME\": null,\n",
      "    \"VORNAME\": null,\n",
      "    \"ORT\": null,\n",
      "    \"Feld1\": null,\n",
      "    \"PSEUDONYM\": null,\n",
      "    \"GESCHLECHT\": null,\n",
      "    \"JAHRGANG\": null,\n",
      "    \"IPV\": null,\n",
      "    \"DATENBOGEN\": null,\n",
      "    \"KURZBESCHR\": null,\n",
      "    \"TITEL\": null,\n",
      "    \"STRASSE\": null,\n",
      "    \"PLZ\": null,\n",
      "    \"TELEFON\": null,\n",
      "    \"GRUPPE\": null,\n",
      "    \"BERUF\": null,\n",
      "    \"HEUT_FAMST\": null,\n",
      "    \"INTERVIEWE\": null,\n",
      "    \"TIPPER\": null,\n",
      "    \"Segmentierung\": null,\n",
      "    \"DATUM1\": null,\n",
      "    \"DATUM2\": null,\n",
      "    \"DATUM3\": null,\n",
      "    \"DAUER\": null,\n",
      "    \"online\": null,\n",
      "    \"AUSDRUCKSART\": null,\n",
      "    \"UNKAUSDRUC\": null,\n",
      "    \"KORRAUSDRU\": null,\n",
      "    \"SCHLAGWORT\": null,\n",
      "    \"KURZBIOGRA\": null,\n",
      "    \"KURZPROTOK\": null,\n",
      "    \"FOTOS\": null,\n",
      "    \"DOKUMENTE\": null,\n",
      "    \"VHS\": null,\n",
      "    \"DVD\": null,\n",
      "    \"IBM Server\": null,\n",
      "    \"Cloud\": null,\n",
      "    \"Format Cloud\": null,\n",
      "    \"DV\": null,\n",
      "    \"Beta\": null,\n",
      "    \"ORIGCASSET\": null,\n",
      "    \"CASSKOPIEN\": null,\n",
      "    \"FESTPLATTE\": null,\n",
      "    \"Dig Audiofiles\": null,\n",
      "    \"KONF_HEUTE\": null,\n",
      "    \"KONVERSION\": null,\n",
      "    \"WANN_KONV\": null,\n",
      "    \"HERKUNFT\": null,\n",
      "    \"WANN_ZUGEZ\": null,\n",
      "    \"GESCHWISTE\": null,\n",
      "    \"Schulabsch\": null,\n",
      "    \"ABGEBROCHE\": null,\n",
      "    \"WEITERBILD\": null,\n",
      "    \"AUSBILDUNG\": null,\n",
      "    \"STAND\": null,\n",
      "    \"WIRTSCHBER\": null,\n",
      "    \"BERUFSWECH\": null,\n",
      "    \"WANN_WECHS\": null,\n",
      "    \"AUFABSTIEG\": null,\n",
      "    \"BERUFSBEGI\": null,\n",
      "    \"BERUFSENDE\": null,\n",
      "    \"NICHTERWER\": null,\n",
      "    \"GRÜNDE\": null,\n",
      "    \"VON_BIS\": null,\n",
      "    \"ARBEITSLOS\": null,\n",
      "    \"VON_BIS_AL\": null,\n",
      "    \"FAM_STAND\": null,\n",
      "    \"HEIRAT1JHR\": null,\n",
      "    \"HEIRAT2JHR\": null,\n",
      "    \"HEIRAT3JHR\": null,\n",
      "    \"SCHEID1JHR\": null,\n",
      "    \"SCHEID2JHR\": null,\n",
      "    \"VERWIT1JHR\": null,\n",
      "    \"VERWIT2JHR\": null,\n",
      "    \"KINDERZAHL\": null,\n",
      "    \"GEB_JAHR1\": null,\n",
      "    \"GEB_JAHR2\": null,\n",
      "    \"GEB_JAHR_L\": null,\n",
      "    \"AUFABKIND\": null,\n",
      "    \"POLOR_HEUT\": null,\n",
      "    \"POL_KONVER\": null,\n",
      "    \"POLORIENT1\": null,\n",
      "    \"VON_BIS_1\": null,\n",
      "    \"POLORIENT2\": null,\n",
      "    \"VON_BIS_2\": null,\n",
      "    \"GEW_VERBAN\": null,\n",
      "    \"VON_BIS_GV\": null,\n",
      "    \"JUGENDORG1\": null,\n",
      "    \"VON_BIS_J1\": null,\n",
      "    \"JUGENDORG2\": null,\n",
      "    \"VON_BIS_J2\": null,\n",
      "    \"NS_ORGAN_1\": \"NSV\",\n",
      "    \"VON_BISNS1\": null,\n",
      "    \"NS_ORGAN_2\": null,\n",
      "    \"VON_BISNS2\": null,\n",
      "    \"RAD_KLV_DV\": \"ja\",\n",
      "    \"VON_BISRAD\": \"November 1942\",\n",
      "    \"SONST_ENG\": null,\n",
      "    \"VON_BIS_SE\": null,\n",
      "    \"KRIEGSTEIL\": null,\n",
      "    \"VON_BIS_KR\": null,\n",
      "    \"BES_BERICH\": null,\n",
      "    \"MUTT_JG\": null,\n",
      "    \"MUTT_KONFESSION\": null,\n",
      "    \"MUTT_HERKU\": null,\n",
      "    \"MUTT_SCHUL\": null,\n",
      "    \"MUTT_AUSBI\": null,\n",
      "    \"MUTT_STAND\": null,\n",
      "    \"MUTT_POLOR\": null,\n",
      "    \"VAT_JG\": null,\n",
      "    \"VAT_KONFESSION\": null,\n",
      "    \"VAT_HERKUN\": null,\n",
      "    \"VAT_SCHULE\": null,\n",
      "    \"VAT_AUSBIL\": null,\n",
      "    \"VAT_STAND\": null,\n",
      "    \"VAT_POLOR\": null,\n",
      "    \"PART_JG\": null,\n",
      "    \"PART_KONFESSION\": null,\n",
      "    \"PART_HERKU\": null,\n",
      "    \"PART_SCHUL\": null,\n",
      "    \"PART_AUSBI\": null,\n",
      "    \"PART_STAND\": null,\n",
      "    \"PART_BERUF\": null,\n",
      "    \"PART_POLOR\": null,\n",
      "    \"PART_PKONV\": null,\n",
      "    \"PART_ENGAG\": null,\n",
      "    \"KRIT10\": null\n",
      "  }\n",
      "]\n",
      "\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jkng267af8aa3gy2hazjmd8h` service tier `on_demand` on : Limit 100000, Used 99177, Requested 1822. Please try again in 14m22.896s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18184/1485610541.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# Extract metadata for the chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mllama_70b_responses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_metadate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_chunks_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata_schema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mllama_70b_responses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18184/4124036287.py\u001b[0m in \u001b[0;36mextract_metadate\u001b[1;34m(client, model_name, chunks, metadata_schema)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# Generate response using AI model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         response = client.chat.completions.create(\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"role\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"user\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"content\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshita\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\groq\\resources\\chat\\completions.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    296\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \"\"\"\n\u001b[1;32m--> 298\u001b[1;33m         return self._post(\n\u001b[0m\u001b[0;32m    299\u001b[0m             \u001b[1;34m\"/openai/v1/chat/completions\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m             body=maybe_transform(\n",
      "\u001b[1;32mc:\\users\\harshita\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\groq\\_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1261\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m         )\n\u001b[1;32m-> 1263\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     def patch(\n",
      "\u001b[1;32mc:\\users\\harshita\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\groq\\_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m         return self._request(\n\u001b[0m\u001b[0;32m    956\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\harshita\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\groq\\_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Re-raising status error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1058\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m         return self._process_response(\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jkng267af8aa3gy2hazjmd8h` service tier `on_demand` on : Limit 100000, Used 99177, Requested 1822. Please try again in 14m22.896s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': '', 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define Paths\n",
    "folder_path = r\"C:\\Users\\Harshita\\Downloads\\case study\\Transcripts\"\n",
    "schema_file = r\"C:\\Users\\Harshita\\Downloads\\case study\\metadata_schema.json\"\n",
    "MODEL = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "# Load Metadata Schema from JSON\n",
    "with open(schema_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata_schema = json.load(f)\n",
    "\n",
    "# List to store metadata for all files\n",
    "all_metadata = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    if os.path.isfile(file_path) and filename.endswith(\".csv\"):\n",
    "        print(f\"\\nProcessing file: {filename}\")\n",
    "\n",
    "        # Load transcript CSV\n",
    "        input_data = pd.read_csv(file_path, sep=None, engine='python')\n",
    "\n",
    "        # Process transcript into chunks\n",
    "        speaker_chunks_df = chunk_transcript(input_data)\n",
    "        final_chunks_df = chunk_by_sentence(speaker_chunks_df)\n",
    "\n",
    "        # Create timestamp column\n",
    "        final_chunks_df[\"Timestamp\"] = final_chunks_df[\"Initial_Timestamp\"] + \" - \" + final_chunks_df[\"Current_Timestamp\"]\n",
    "        final_chunks_df.drop(columns=[\"Initial_Timestamp\", \"Current_Timestamp\"], inplace=True)\n",
    "\n",
    "        # Extract metadata for the chunks\n",
    "        llama_70b_responses = extract_metadate(client, MODEL, final_chunks_df, metadata_schema)\n",
    "\n",
    "        if not llama_70b_responses.empty:\n",
    "            # Merge chunk outputs into a single row\n",
    "            merged_metadata = llama_70b_responses.apply(lambda col: ' | '.join(col.dropna().astype(str)))\n",
    "\n",
    "            for column in merged_metadata.index:\n",
    "                unique_values = set(value.strip() for value in merged_metadata[column].strip().split(\",\"))\n",
    "                merged_metadata[column] = \" | \".join(filter(None, unique_values))\n",
    "\n",
    "            # Append to list\n",
    "            all_metadata.append(merged_metadata)\n",
    "        else:\n",
    "            print(f\"No metadata extracted from {filename}\")\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# Convert list of metadata rows into a single DataFrame\n",
    "final_metadata_df = pd.DataFrame(all_metadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13f3809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_metadata(client, model_name: str, chunks: pd.DataFrame, metadata_schema: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract metadata from multiple chunks of a transcript using the specified model.\n",
    "\n",
    "    Args:\n",
    "        client: The AI client object.\n",
    "        model_name: The AI model to use.\n",
    "        chunks: A DataFrame with 'Speaker' and 'Transcript' columns.\n",
    "        metadata_schema: A dictionary representing the metadata schema.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A structured DataFrame containing extracted metadata.\n",
    "    \"\"\"\n",
    "    all_metadata = []\n",
    "\n",
    "    for i, row in chunks.iterrows():\n",
    "        speaker = row[\"Speaker\"]\n",
    "        transcript = row[\"Transcript\"][:1500]  # Prevent AI truncation\n",
    "        timestamp = row[\"Timestamp\"]\n",
    "\n",
    "        # Convert schema to JSON format\n",
    "        schema_json = json.dumps(metadata_schema, indent=2)\n",
    "\n",
    "        # JSON-structured prompt\n",
    "        prompt = f\"\"\"\n",
    "       \n",
    "        You are a highly skilled metadata extraction AI. Your task is to analyze the provided transcript \n",
    "        and extract structured metadata according to a predefined schema. The metadata schema contains field names and their descriptions.\n",
    "\n",
    "        **Your Task:**\n",
    "        1. Extract relevant metadata from the transcript while adhering **strictly** to the JSON schema.\n",
    "        2. Fields labeled `\"IGNORE\"` should **not be discarded**—instead, use the column name as its description.\n",
    "        3. If information is **missing** in the transcript, infer a reasonable value or set it to `\"null\"`.\n",
    "        4. Ensure all required fields are included and that the extracted metadata is in **valid JSON format**.\n",
    "\n",
    "        ** Metadata Extraction Schema**\n",
    "        Extract metadata using the **following JSON schema**:\n",
    "\n",
    "        ```json\n",
    "        {schema_json}\n",
    "        ```\n",
    "\n",
    "        Transcript:\n",
    "        {transcript}\n",
    "        \"\"\"\n",
    "\n",
    "        # Generate response using AI model\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        # Extract raw response\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Fix Hidden JSON Formatting Issues\n",
    "        response_text = response_text.strip(\"`\")  # Remove possible markdown backticks\n",
    "        response_text = re.sub(r'```json|```', '', response_text).strip()  # Remove ```json blocks\n",
    "\n",
    "        # Parse AI response to JSON\n",
    "        try:\n",
    "            metadata = json.loads(response_text)  # Convert response to JSON\n",
    "        except json.JSONDecodeError:\n",
    "            continue  # Skip this chunk if JSON parsing fails\n",
    "\n",
    "        # Clean metadata: remove invalid values\n",
    "        extracted_metadata = {key: value if value not in [\"%%%\", None, \"\", \"null\"] else None for key, value in metadata.items()}\n",
    "        extracted_metadata[\"Speaker\"] = speaker\n",
    "        extracted_metadata[\"Timestamp\"] = timestamp\n",
    "\n",
    "        all_metadata.append(extracted_metadata)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(all_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d29482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
